ðŸ§  **Gen AI & LLM Engineering â€” Labs, Patterns & Playbooks**

â€œLearn by building. Ship small, ship often, and let data guide the next step.â€
Welcome! This repository is a hands-on learning hub for modern Gen AI & LLM engineering. It blends notebooks, mini-projects, and slides to help you master real-world patterns across open and closed-source models, multimodality, inference & evaluation, conversational chatbots, tool use (function calling), and RAG systemsâ€”from idea to production.

ðŸ”Ž **Whatâ€™s inside**

/notebooks/ â€“ step-by-step labs (prompting, context/memory, tools, RAG, multimodal, evaluation)
/projects/ â€“ runnable reference apps (chatbot, voice assistant, RAG search, agents)
/providers/ â€“ example calls across providers (OpenAI, Anthropic, Google, Mistral, DeepSeek, HuggingFace/Ollama)
/utils/ â€“ helper clients, tracing, metrics, prompts, dataset loaders
/slides/ â€“ teaching decks for each module
/resources/ â€“ reading lists, papers, system design checklists

Designed for learners who want production-grade patterns, not just toy examples.


**LLM Coding â€“ Python Environment Setup**
Please follow the below steps to set up your Python environment for LLM Coding and refer to cusrsor IDE , UV installation , API key setup in the next slides.

1. Clone the github repo into your local project folder by running this clone command â€œgit clone https://github.com/rathina4aicoding/AI-Coding.gitâ€ (This is the project folder that will be opened up in your cursor IDE as cursor Project folder) 
2. Cursor setup â€“ Free download from https://www.cursor.com/ , install it and complete the setup.
3. Set up your project folders in your local ; For Eg. C:\Users\rathi\Projects\AI-Coding\llm-coding\
4. Open the local project folder (C:\Users\rathi\Projects\AI-Coding\llm-coding\) from your Cursor IDE
5. Add the pyproject.toml & uv.lock files into your project folder in Cursor. (Rathina will share these 2 files)
6. Download UV Package Manager from https://docs.astral.sh/uv/getting-started/installation/#__tabbed_1_1 and install it in your machine (windows/mac)
7. Run the command â€œuv syncâ€ in the terminal to install all the libraries and dependencies from pyproject.toml & uv.lock files. 
8. Create a .env file in the same project folder in cursor to add your API keys from respective model providers such as OpenAI, Anthropic, Google, Deepseek etc
9. Create an account for each LLM Model provider tech company , create API keys and add then into .env file as shown below
OPENAI_API_KEY=xxxx
ANTHROPIC_API_KEY=xxxx
GOOGLE_API_KEY=xxxx
DEEPSEEK_API_KEY=xxxx

You are all set to go for LLM Coding!!!

**UV Python Package Manager â€“ Setup**

Follow the instructions here to install uv - I recommend using the Standalone Installer approach at the very top:

https://docs.astral.sh/uv/getting-started/installation/

Then within Cursor, select View >> Terminal, to see a Terminal window within Cursor.
Type â€œpwdâ€ to see the current directory, and navigate to your project directory â€“ For Eg C:\Users\rathi\Projects\AI-Coding\llm-coding\

Run below command to install UV for Windows 
>> powershell -ExecutionPolicy ByPass -c "irm https://astral.sh/uv/install.ps1 | iexâ€œ

For Mac or Linux
>> curl -LsSf https://astral.sh/uv/install.sh | sh

If your system doesn't have curl, you can use wget:
>> wget -qO- https://astral.sh/uv/install.sh | sh

Request a specific version by including it in the URL:
>> curl -LsSf https://astral.sh/uv/0.8.12/install.sh | sh

Start by running uv self update to make sure you're on the latest version of uv.

Note: One thing to watch for: if you've used Anaconda before, make sure that your Anaconda environment is deactivated
>> conda deactivate
And if you still have any problems with conda and python versions, it's possible that you will need to run this too:
>> conda config --set auto_activate_base false

And now simply run:
>> uv sync
And marvel at the speed and reliability! If necessary, uv should install python 3.12, and then it should install all the packages.

If you get an error about "invalid certificate" while running uv sync, then please try this instead:
>> uv --native-tls sync

And also try this instead:
>> uv --allow-insecure-host github.com sync

**LLM Calling- API Key Setup**

API Key Setup

For OpenAI, visit https://openai.com/api/  

For Anthropic, visit https://console.anthropic.com/
 
For Google, visit https://ai.google.dev/gemini-api


### Also - adding DeepSeek if you wish

Optionally, if you'd like to also use DeepSeek, create an account [here](https://platform.deepseek.com/), create a key [here](https://platform.deepseek.com/api_keys) and top up with at least the minimum $2 [here] (https://platform.deepseek.com/top_up).

### Adding API keys to your .env file


When you get your API keys, you need to set them as environment variables by adding them to your `.env` file.

```
OPENAI_API_KEY=xxxx
ANTHROPIC_API_KEY=xxxx
GOOGLE_API_KEY=xxxx
DEEPSEEK_API_KEY=xxxx

```

Afterwards, you may need to restart the Jupyter Lab Kernel (the Python process that sits behind this notebook) via the Kernel menu, and then rerun the cells from the top.







