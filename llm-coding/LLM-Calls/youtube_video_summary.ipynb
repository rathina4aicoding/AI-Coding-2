{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce1cf91c",
   "metadata": {},
   "source": [
    "# Youtube Video Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b857101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c73f8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube_transcript_api in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from youtube_transcript_api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from youtube_transcript_api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rathi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->youtube_transcript_api) (2024.8.30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\rathi\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install youtube_transcript_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0575ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "666f4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df7930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "class YouTubeWebLink:\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.video_id = self.get_video_id(url)\n",
    "        self.set_openai_client()\n",
    "        self.set_system_prompt()\n",
    "\n",
    "    def get_video_id(self, url):\n",
    "        \"\"\" extract youtube video id from url with regular expression \"\"\"\n",
    "        regex = r\"(?:v=|be/)([a-zA-Z0-9_-]{11})\"\n",
    "        match = re.search(regex, url)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "        else:\n",
    "            raise ValueError(\"Probably not a YouTube URL\")\n",
    "        \n",
    "    def set_openai_client(self):\n",
    "        self.openai = OpenAI()\n",
    "        \n",
    "    def set_system_prompt(self, system_prompt=None):\n",
    "        \"\"\" set system prompt from youtube video \"\"\"\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a skilled explainer and storyteller who specializes in summarizing YouTube video transcripts in a way that's both engaging and informative. \n",
    "        Your task is to:\n",
    "        - Capture key points and main ideas of the video\n",
    "        - Structure your summary with in clear sections\n",
    "        - Include important details, facts, and figures mentioned\n",
    "        - Never end your summary with a \"Conclusion\" section\n",
    "        - Keep the summary short and easy to understand\n",
    "        - Always format your response in markdown for better readability\n",
    "        \"\"\" if system_prompt is None else system_prompt\n",
    "\n",
    "    def get_transcript(self):\n",
    "        \"\"\" get transcript from youtube video \"\"\"\n",
    "        try:\n",
    "           print('Fetching video transcript...')\n",
    "           transcript = YouTubeTranscriptApi().fetch(self.video_id)\n",
    "           # Fixed: Access the text attribute instead of dictionary key\n",
    "           return \" \".join([item.text for item in transcript])\n",
    "        except Exception as e:\n",
    "           print(f\"Error fetching transcript: {e}\")\n",
    "           return None\n",
    "        \n",
    "    def get_summary_from_transcript(self, transcript):\n",
    "        \"\"\" summarize text using openai \"\"\"\n",
    "        try:\n",
    "            print('Summarizing video...')\n",
    "            response = self.openai.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"Summarize the following YouTube video transcript:\\n\\n{transcript}\"}\n",
    "                ]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            print(f\"Error summarizing text: {e}\")\n",
    "            return None\n",
    "\n",
    "    def display_summary(self):\n",
    "        \"\"\" summarize youtube video \"\"\"\n",
    "        transcript = self.get_transcript()\n",
    "        if transcript:\n",
    "            summary = self.get_summary_from_transcript(transcript)\n",
    "            if summary:\n",
    "                display(Markdown(summary))\n",
    "            else:\n",
    "                print(\"Failed to generate summary\")\n",
    "        else:\n",
    "            print(\"Failed to fetch transcript\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "068863dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video link and share link of same youtube video\n",
    "test_url_1 = \"https://www.youtube.com/watch?v=pu3-PeBG0YU\"\n",
    "test_url_2 = \"https://www.youtube.com/watch?v=EDb37y_MhRw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6445e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('pu3-PeBG0YU', 'EDb37y_MhRw')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test that we get same id\n",
    "video1, video2 = YouTubeWebLink(test_url_1), YouTubeWebLink(test_url_2)\n",
    "video1.video_id, video2.video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f812b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching video transcript...\n",
      "Summarizing video...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Summary of Generative AI Fine-Tuning\n",
       "\n",
       "## Introduction to Fine-Tuning Generative AI\n",
       "The video discusses how to specialize a large language model (LLM) for specific use cases without needing advanced technical skills. It emphasizes that while LLMs are effective for general queries, they excel only when trained on domain-specific data.\n",
       "\n",
       "## Steps to Fine-Tuning an AI Model\n",
       "The process of fine-tuning involves three main steps:\n",
       "\n",
       "1. **Data Curation**\n",
       "   - Collect relevant data that reflects the knowledge and skills you want the model to acquire.\n",
       "   - The video demonstrates the use of the open-source project **InstructLab**, making it accessible for anyone to contribute.\n",
       "\n",
       "2. **Synthetic Data Generation**\n",
       "   - Fine-tuning typically requires large datasets, so the presenter explains how to use an LLM running locally to create synthetic data from curated examples.\n",
       "   - For instance, a question about Oscar nominations is posed to demonstrate the model's initial inaccuracies.\n",
       "\n",
       "3. **Parameter Efficient Fine-Tuning**\n",
       "   - The final step involves integrating the new knowledge into the model with minimal updates to its parameters, allowing the process to be performed on a consumer-grade laptop.\n",
       "\n",
       "## Practical Application of InstructLab\n",
       "- The video showcases how to set up InstructLab and prepare a working directory.\n",
       "- It illustrates the creation of a hierarchy for organizing training data and generating additional examples based on initial inputs.\n",
       "\n",
       "## Results of Fine-Tuning\n",
       "- After fine-tuning, the model is tested with the example question about Oscar nominations, providing the correct answer, “Oppenheimer.”\n",
       "- The process demonstrates the transformation from a general model to a specialized one capable of producing accurate domain-specific responses.\n",
       "\n",
       "## Community and Future Potential\n",
       "- The presenter highlights the vision of open-source AI, advocating for community contributions and collaboration on specialized models.\n",
       "- Use cases are provided, including applications in insurance claims management and legal contract processing.\n",
       "\n",
       "## Call to Action\n",
       "To conclude, the video encourages viewers to explore the possibilities of creating specialized AI models and invites interaction through comments regarding users' interests in this technology. \n",
       "\n",
       "The presentation offers an empowering message that anyone can fine-tune an LLM using accessible tools and contribute to the growing AI landscape, making it a valuable resource for professionals across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video1.display_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
